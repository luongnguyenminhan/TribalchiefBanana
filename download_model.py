#!/usr/bin/env python3
"""
Script Ä‘á»ƒ download model HuggingFace trong quÃ¡ trÃ¬nh build Docker
Sáº½ download model vÃ o cache Ä‘á»ƒ runtime khÃ´ng cáº§n download
"""

from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import os
import sys

MODEL_NAME = "tarudesu/ViHateT5-base-HSD"


def download_model():
    """Download model vÃ  tokenizer vÃ o cache"""
    print(f"ğŸ”„ Downloading model: {MODEL_NAME}")

    try:
        # Download tokenizer
        print("ğŸ“ Downloading tokenizer...")
        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
        print(f"âœ… Tokenizer downloaded successfully")

        # Download model
        print("ğŸ¤– Downloading model...")
        model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)
        print(f"âœ… Model downloaded successfully")

        # Test model Ä‘á»ƒ Ä‘áº£m báº£o hoáº¡t Ä‘á»™ng
        print("ğŸ§ª Testing model...")
        test_input = "toxic-speech-detection: xin chÃ o"
        input_ids = tokenizer.encode(test_input, return_tensors="pt")
        output_ids = model.generate(input_ids, max_length=256)
        output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)
        print(f"âœ… Model test successful: {output_text}")

        # In thÃ´ng tin cache
        cache_dir = os.environ.get("TRANSFORMERS_CACHE", "~/.cache/huggingface")
        print(f"ğŸ“¦ Model cached in: {cache_dir}")

        return True

    except Exception as e:
        print(f"âŒ Error downloading model: {e}")
        return False


if __name__ == "__main__":
    success = download_model()
    if not success:
        sys.exit(1)
    print("ğŸ‰ Model download completed successfully!")
